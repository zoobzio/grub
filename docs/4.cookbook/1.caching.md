---
title: Caching Patterns
description: Cache-aside and other caching patterns with grub
author: zoobzio
published: 2025-12-17
updated: 2025-12-17
tags:
  - cookbook
  - caching
  - patterns
  - redis
---

# Caching Patterns

This recipe covers common caching patterns using grub with Redis or other fast providers.

## The Scenario

You have a primary database (e.g., PostgreSQL, MongoDB) and want to add a caching layer to reduce latency and database load.

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│ Application │────▶│    Cache    │────▶│  Database   │
│             │◀────│   (Redis)   │◀────│ (Primary)   │
└─────────────┘     └─────────────┘     └─────────────┘
```

## Cache-Aside Pattern

The most common caching pattern. Application manages cache explicitly.

### Implementation

```go
type CachedUserService struct {
    cache    *grub.Service[User]
    database *grub.Service[User]
}

func NewCachedUserService(cacheProvider, dbProvider grub.Provider) *CachedUserService {
    return &CachedUserService{
        cache:    grub.New[User](cacheProvider),
        database: grub.New[User](dbProvider),
    }
}

func (s *CachedUserService) Get(ctx context.Context, id string) (*User, error) {
    // Try cache first
    user, err := s.cache.Get(ctx, id)
    if err == nil {
        return &user, nil  // Cache hit
    }

    if !errors.Is(err, grub.ErrNotFound) {
        // Cache error - log and continue to database
        log.Printf("Cache error: %v", err)
    }

    // Cache miss - fetch from database
    user, err = s.database.Get(ctx, id)
    if err != nil {
        return nil, err
    }

    // Populate cache (best effort)
    if cacheErr := s.cache.Set(ctx, id, user); cacheErr != nil {
        log.Printf("Failed to cache user: %v", cacheErr)
    }

    return &user, nil
}

func (s *CachedUserService) Set(ctx context.Context, user User) error {
    // Write to database first
    if err := s.database.Set(ctx, user.ID, user); err != nil {
        return err
    }

    // Invalidate cache
    s.cache.Delete(ctx, user.ID)

    return nil
}

func (s *CachedUserService) Delete(ctx context.Context, id string) error {
    // Delete from database
    if err := s.database.Delete(ctx, id); err != nil {
        return err
    }

    // Invalidate cache
    s.cache.Delete(ctx, id)

    return nil
}
```

### Characteristics

- **Lazy population**: Cache fills on first read
- **Eventual consistency**: Brief window where cache may be stale
- **Cache misses are expensive**: Full database round-trip on miss

## Write-Through Pattern

Cache is updated synchronously with database writes.

### Implementation

```go
func (s *CachedUserService) Set(ctx context.Context, user User) error {
    // Write to database
    if err := s.database.Set(ctx, user.ID, user); err != nil {
        return err
    }

    // Write to cache (synchronous)
    if err := s.cache.Set(ctx, user.ID, user); err != nil {
        // Rollback or handle inconsistency
        log.Printf("Cache write failed: %v", err)
    }

    return nil
}
```

### Characteristics

- **Strong consistency**: Cache always reflects database
- **Higher write latency**: Two writes per operation
- **No cold cache problem**: Data cached on write

## Read-Through Pattern

Cache automatically fetches from database on miss.

### Implementation

```go
type ReadThroughCache struct {
    cache    *grub.Service[User]
    loader   func(ctx context.Context, id string) (User, error)
    mu       sync.Map  // Prevent thundering herd
}

func (c *ReadThroughCache) Get(ctx context.Context, id string) (*User, error) {
    // Try cache
    user, err := c.cache.Get(ctx, id)
    if err == nil {
        return &user, nil
    }

    if !errors.Is(err, grub.ErrNotFound) {
        return nil, err
    }

    // Prevent thundering herd with singleflight pattern
    ch := make(chan struct{})
    actual, loaded := c.mu.LoadOrStore(id, ch)
    if loaded {
        // Another goroutine is loading - wait
        <-actual.(chan struct{})
        return c.Get(ctx, id)  // Retry from cache
    }
    defer func() {
        c.mu.Delete(id)
        close(ch)
    }()

    // Load from source
    user, err = c.loader(ctx, id)
    if err != nil {
        return nil, err
    }

    // Cache result
    c.cache.Set(ctx, id, user)

    return &user, nil
}
```

### Characteristics

- **Automatic loading**: Application doesn't manage cache explicitly
- **Thundering herd protection**: Single load for concurrent requests
- **More complex**: Requires coordination logic

## Cache Invalidation

### Time-Based Invalidation

For Redis, use native TTL. For other providers, store expiration:

```go
type CacheEntry[T any] struct {
    Value     T         `json:"value"`
    ExpiresAt time.Time `json:"expires_at"`
}

func (c *Cache[T]) Get(ctx context.Context, key string) (*T, error) {
    entry, err := c.store.Get(ctx, key)
    if err != nil {
        return nil, err
    }

    if time.Now().After(entry.ExpiresAt) {
        c.store.Delete(ctx, key)
        return nil, grub.ErrNotFound
    }

    return &entry.Value, nil
}

func (c *Cache[T]) Set(ctx context.Context, key string, value T, ttl time.Duration) error {
    entry := CacheEntry[T]{
        Value:     value,
        ExpiresAt: time.Now().Add(ttl),
    }
    return c.store.Set(ctx, key, entry)
}
```

### Event-Based Invalidation

Invalidate cache when database changes:

```go
// Hook into database write events
capitan.Hook(userUpdated, func(ctx context.Context, e *capitan.Event) {
    userID := FieldUserID.From(e)
    cache.Delete(ctx, userID)
})
```

### Version-Based Invalidation

Include version in cache key:

```go
func cacheKey(userID string, version int) string {
    return fmt.Sprintf("user:%s:v%d", userID, version)
}

func (s *Service) Get(ctx context.Context, id string, version int) (*User, error) {
    key := cacheKey(id, version)
    return s.cache.Get(ctx, key)
}
```

## Cache Warming

Pre-populate cache on startup or schedule:

```go
func warmCache(ctx context.Context, cache, db *grub.Service[User]) error {
    cursor := ""

    for {
        keys, nextCursor, err := db.List(ctx, cursor, 100)
        if err != nil {
            return err
        }

        for _, key := range keys {
            user, err := db.Get(ctx, key)
            if err != nil {
                continue
            }
            cache.Set(ctx, key, user)
        }

        if nextCursor == "" {
            return nil
        }
        cursor = nextCursor
    }
}
```

## Multi-Level Cache

Layer caches for different access patterns:

```go
type MultiLevelCache struct {
    l1 *grub.Service[User]  // Local (BadgerDB)
    l2 *grub.Service[User]  // Distributed (Redis)
    db *grub.Service[User]  // Primary (MongoDB)
}

func (c *MultiLevelCache) Get(ctx context.Context, id string) (*User, error) {
    // L1: Local cache
    if user, err := c.l1.Get(ctx, id); err == nil {
        return &user, nil
    }

    // L2: Distributed cache
    if user, err := c.l2.Get(ctx, id); err == nil {
        c.l1.Set(ctx, id, user)  // Populate L1
        return &user, nil
    }

    // Database
    user, err := c.db.Get(ctx, id)
    if err != nil {
        return nil, err
    }

    // Populate both cache levels
    c.l2.Set(ctx, id, user)
    c.l1.Set(ctx, id, user)

    return &user, nil
}
```

## Observability

Track cache hit rates:

```go
var (
    cacheHits   int64
    cacheMisses int64
)

func (s *CachedService) Get(ctx context.Context, id string) (*User, error) {
    user, err := s.cache.Get(ctx, id)
    if err == nil {
        atomic.AddInt64(&cacheHits, 1)
        return &user, nil
    }

    atomic.AddInt64(&cacheMisses, 1)
    // ... fetch from database
}

func HitRate() float64 {
    hits := atomic.LoadInt64(&cacheHits)
    misses := atomic.LoadInt64(&cacheMisses)
    total := hits + misses
    if total == 0 {
        return 0
    }
    return float64(hits) / float64(total)
}
```

## Testing

```go
func TestCacheAside(t *testing.T) {
    cacheProvider := grubtesting.NewMockProvider()
    dbProvider := grubtesting.NewMockProvider()

    svc := NewCachedUserService(cacheProvider, dbProvider)
    ctx := context.Background()

    // Setup database
    user := User{ID: "usr-123", Name: "Alice"}
    dbProvider.Set(ctx, "users:usr-123", mustMarshal(user))

    // First read - cache miss
    got, err := svc.Get(ctx, "usr-123")
    if err != nil {
        t.Fatal(err)
    }
    if got.Name != "Alice" {
        t.Errorf("expected Alice, got %s", got.Name)
    }

    // Verify cache populated
    _, err = cacheProvider.Get(ctx, "users:usr-123")
    if err != nil {
        t.Error("expected cache to be populated")
    }

    // Second read - cache hit (delete from DB to prove)
    dbProvider.Delete(ctx, "users:usr-123")
    got, err = svc.Get(ctx, "usr-123")
    if err != nil {
        t.Fatal(err)
    }
    if got.Name != "Alice" {
        t.Error("expected cache hit")
    }
}
```

## See Also

- **[Providers Guide](../3.guides/1.providers.md)** - Configuring Redis and other providers
- **[Multi-tenant Pattern](3.multi-tenant.md)** - Cache isolation per tenant
- **[Best Practices](../3.guides/5.best-practices.md)** - Performance recommendations
